# -*- coding: utf-8 -*-
"""Unet model for gene exspression.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1hpZHMOukpA7yDXvMbQIILXphe3IzUHli

## ğŸ”µ Step 1 â€“ Mount Google Drive and Define Paths
"""

from google.colab import drive
drive.mount('/content/drive')

!pip install pytorch-msssim

# ğŸ” Define paths for original and stained images
original_dir = '/content/drive/MyDrive/final project/Part 3 - Cell Segmentation with Transfer Learning/Data/Original_Images'
stained_dir  = '/content/drive/MyDrive/final project/Part 3 - Cell Segmentation with Transfer Learning/Data/GT_Thresholded'

"""## ğŸ”µ Step 2 â€“ Prepare File Lists and Match Image Pairs

"""

import os
from glob import glob
import torch

# âœ… Use GPU if available
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# ğŸ” Get file paths sorted by filename
original_images = sorted(glob(os.path.join(original_dir, 'Position*.tif')))
stained_images = [
    os.path.join(stained_dir, os.path.basename(p).replace('.tif', '_GT.tif'))
    for p in original_images
]

# âœ… Match check
for o, s in zip(original_images, stained_images):
    assert os.path.exists(s), f"Missing stained file for {o}"

print(f"âœ… Matched {len(original_images)} image pairs.")

"""##ğŸ”µ Step 3 â€“ Define Dataset with Patch Extraction, GT Normalization and Augmentations

"""

from PIL import Image
from torch.utils.data import Dataset
import numpy as np
import albumentations as A
from albumentations.pytorch import ToTensorV2
import cv2

class ExpressionRegressionDataset(Dataset):
    def __init__(self, original_paths, stained_paths, patch_size=512, overlap=0.5, augment=False):
        self.original_paths = original_paths
        self.stained_paths = stained_paths
        self.patch_size = patch_size
        self.stride = int(patch_size * (1 - overlap))
        self.augment = augment

        self.patches = []
        for i, path in enumerate(self.original_paths):
            img = Image.open(path)
            w, h = img.size
            for y in range(0, h - patch_size + 1, self.stride):
                for x in range(0, w - patch_size + 1, self.stride):
                    self.patches.append((i, x, y))

        # âœ… Define augmentation pipeline
        self.aug = A.Compose([
            A.RandomBrightnessContrast(0.3, 0.3, p=0.5),
            A.GaussNoise(var_limit=(10.0, 50.0), p=0.3),
            A.HorizontalFlip(p=0.5),
            A.VerticalFlip(p=0.5),
            A.RandomRotate90(p=0.3),
            A.Cutout(num_holes=5, max_h_size=64, max_w_size=64, fill_value=0, p=0.3),
            A.Normalize(mean=(0.5,), std=(0.5,)),  # RGB normalized to [-1, 1]
            ToTensorV2()
        ])

        self.no_aug = A.Compose([
            A.Normalize(mean=(0.5,), std=(0.5,)),
            ToTensorV2()
        ])

    def __len__(self):
        return len(self.patches)

    def __getitem__(self, idx):
        img_idx, x, y = self.patches[idx]

        img = Image.open(self.original_paths[img_idx]).convert('RGB')
        target = Image.open(self.stained_paths[img_idx]).convert('L')

        img_patch = img.crop((x, y, x + self.patch_size, y + self.patch_size))
        target_patch = target.crop((x, y, x + self.patch_size, y + self.patch_size))

        # Convert to numpy
        img_np = np.array(img_patch)
        target_np = np.array(target_patch, dtype=np.float32) / 255.0  # normalize target to [0,1]

        # Apply augmentation
        if self.augment:
            augmented = self.aug(image=img_np, mask=target_np)
        else:
            augmented = self.no_aug(image=img_np, mask=target_np)

        img_tensor = augmented['image']
        target_tensor = augmented['mask'].unsqueeze(0)  # add channel dimension

        return img_tensor, target_tensor

"""## ğŸ”µ Step 4 â€“ Split, Augment, and Create DataLoaders


"""

from PIL import Image
from torch.utils.data import Dataset, DataLoader
from sklearn.model_selection import train_test_split
import numpy as np
import albumentations as A
from albumentations.pytorch import ToTensorV2
import cv2

# âœ… Dataset class
class ExpressionRegressionDataset(Dataset):
    def __init__(self, original_paths, stained_paths, patch_size=512, overlap=0.5, augment=False):
        self.original_paths = original_paths
        self.stained_paths = stained_paths
        self.patch_size = patch_size
        self.stride = int(patch_size * (1 - overlap))
        self.augment = augment

        self.patches = []
        for i, path in enumerate(self.original_paths):
            img = Image.open(path)
            w, h = img.size
            for y in range(0, h - patch_size + 1, self.stride):
                for x in range(0, w - patch_size + 1, self.stride):
                    self.patches.append((i, x, y))

        # âœ… Augmentations
        self.aug = A.Compose([
            A.HorizontalFlip(p=0.5),
            A.VerticalFlip(p=0.5),
            A.RandomRotate90(p=0.3),
            A.ShiftScaleRotate(shift_limit=0.05, scale_limit=0.05, rotate_limit=10, p=0.3),
            A.Normalize(mean=(0.5,), std=(0.5,)),
            ToTensorV2()
        ])


        self.no_aug = A.Compose([
            A.Normalize(mean=(0.5,), std=(0.5,)),
            ToTensorV2()
        ])

    def __len__(self):
        return len(self.patches)

    def __getitem__(self, idx):
        img_idx, x, y = self.patches[idx]

        img = Image.open(self.original_paths[img_idx]).convert('RGB')
        target = Image.open(self.stained_paths[img_idx]).convert('L')

        img_patch = img.crop((x, y, x + self.patch_size, y + self.patch_size))
        target_patch = target.crop((x, y, x + self.patch_size, y + self.patch_size))

        # Convert to numpy
        img_np = np.array(img_patch)
        target_np = np.array(target_patch, dtype=np.float32) / 255.0

        # Apply augmentations
        if self.augment:
            augmented = self.aug(image=img_np, mask=target_np)
        else:
            augmented = self.no_aug(image=img_np, mask=target_np)

        img_tensor = augmented['image']
        target_tensor = augmented['mask'].unsqueeze(0)

        return img_tensor, target_tensor

# âš™ï¸ Parameters
patch_size = 512
overlap = 0.5
batch_size = 32

# ğŸ”€ Split data
train_ori, test_ori, train_stain, test_stain = train_test_split(
    original_images, stained_images, test_size=0.2, random_state=42
)

# ğŸ“¦ Datasets
train_dataset = ExpressionRegressionDataset(train_ori, train_stain, patch_size, overlap, augment=True)
test_dataset  = ExpressionRegressionDataset(test_ori,  test_stain,  patch_size, overlap, augment=False)

# ğŸ” Loaders
train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=0)
test_loader  = DataLoader(test_dataset,  batch_size=batch_size, shuffle=False, num_workers=0)

print(f"âœ… Loaded {len(train_dataset)} train patches and {len(test_dataset)} test patches.")

"""## ğŸ”µ Step 5 â€“ Define Upgraded UNet++ Model


"""

!pip install -q segmentation-models-pytorch

import segmentation_models_pytorch as smp


model = smp.Unet(
    encoder_name="resnet34",
    encoder_weights="imagenet",
    in_channels=3,
    classes=1,
    activation=None  # Regression â€“ no activation
).to(device)

print("âœ… UNet with ResNet34 initialized.")

"""## ğŸ”µ Step 6 â€“ Define Loss, Optimizer, and Training Loop Setup

"""

import torch
import torch.nn.functional as F
import numpy as np
from pytorch_msssim import ssim
from scipy.ndimage import gaussian_filter1d
import torch.optim as optim

# âœ… Focused loss = weighted Huber loss + SSIM
def focused_loss(pred, target, sigma=0.45, ssim_weight=0, delta=1.0):
    """
    pred, target : shape (B, 1, H, W)
    """
    # ××©×§×•×œ ×œ×¤×™ ×¢×•×¦××ª ×”-GT â€“ ××—×–×§ ×ª××™× ×—×–×§×™×
    weights = torch.exp(-((1.0 - target) ** 2) / (2 * sigma ** 2))
    weights = weights / weights.mean()

    # Weighted Huber Loss
    huber = F.smooth_l1_loss(pred, target, reduction='none', beta=delta)
    weighted_huber = (huber * weights).mean()

    # SSIM Loss
    ssim_val = ssim(pred, target, data_range=1.0, size_average=True)
    ssim_loss = 1 - ssim_val

    return (1 - ssim_weight) * weighted_huber + ssim_weight * ssim_loss

# âš™ï¸ Optimizer + LR scheduler
optimizer = optim.Adam(model.parameters(), lr=1e-4, weight_decay=1e-5)
scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=4, verbose=True)

# ğŸ” Training setup
num_epochs = 30
train_losses = []
test_losses = []

print("âœ… Weighted Huber + SSIM loss and optimizer set.")

"""## ğŸ”µ Step 7 â€“ Training Loop with Early Stopping and Model Saving


"""

import os
import matplotlib.pyplot as plt
import time

best_loss = float('inf')
save_path = '/content/drive/MyDrive/final project/unetpp_best_model.pth'

for epoch in range(num_epochs):
    start_time = time.time()
    model.train()
    train_loss = 0.0

    for images, targets in train_loader:
        images = images.to(device)
        targets = targets.to(device)

        optimizer.zero_grad()
        outputs = model(images)
        loss = focused_loss(outputs, targets)
        loss.backward()
        optimizer.step()

        train_loss += loss.item() * images.size(0)

    epoch_train_loss = train_loss / len(train_loader.dataset)
    train_losses.append(epoch_train_loss)

    # Evaluation
    model.eval()
    test_loss = 0.0
    with torch.no_grad():
        for images, targets in test_loader:
            images = images.to(device)
            targets = targets.to(device)
            outputs = model(images)
            loss = focused_loss(outputs, targets)
            test_loss += loss.item() * images.size(0)

    epoch_test_loss = test_loss / len(test_loader.dataset)
    test_losses.append(epoch_test_loss)

    # Scheduler step
    scheduler.step(epoch_test_loss)

    # Save best model
    if epoch_test_loss < best_loss:
        best_loss = epoch_test_loss
        torch.save(model.state_dict(), save_path)
        print(f"âœ… Epoch {epoch+1}: New best model saved! Test Loss = {epoch_test_loss:.4f}")
    else:
        print(f"Epoch {epoch+1}/{num_epochs} | Train Loss: {epoch_train_loss:.4f} | Test Loss: {epoch_test_loss:.4f}")

    elapsed = time.time() - start_time
    print(f"Epoch duration: {elapsed:.2f} seconds")

import matplotlib.pyplot as plt

plt.figure(figsize=(8, 5))
plt.plot(range(1, len(train_losses)+1), train_losses, label='Train Loss')
plt.plot(range(1, len(test_losses)+1), test_losses, label='Test Loss')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.title('Train vs Test Loss')
plt.legend()
plt.grid(True)
plt.show()

"""## ğŸ”µ Step 9 â€“ Predict Full Image Using Overlapping Patches










"""

for i, (full_img_path, gt_path) in enumerate(zip(test_ori, test_stain)):
    full_img = Image.open(full_img_path).convert('RGB')
    full_img_np = np.array(full_img)
    H, W, _ = full_img_np.shape

    output_map = np.zeros((H, W), dtype=np.float32)
    counter_map = np.zeros((H, W), dtype=np.float32)

    model.eval()
    with torch.no_grad():
        for y in range(0, H - patch_size + 1, stride):
            for x in range(0, W - patch_size + 1, stride):
                patch = full_img_np[y:y+patch_size, x:x+patch_size, :]
                patch_tensor = torch.from_numpy(patch / 255.0).permute(2, 0, 1).unsqueeze(0)
                patch_tensor = (patch_tensor - 0.5) / 0.5
                patch_tensor = patch_tensor.to(device).float()

                pred = model(patch_tensor).squeeze().cpu().numpy()
                output_map[y:y+patch_size, x:x+patch_size] += pred
                counter_map[y:y+patch_size, x:x+patch_size] += 1

    counter_map[counter_map == 0] = 1
    final_prediction = output_map / counter_map

    # Load GT
    gt_gray = Image.open(gt_path).convert('L')
    gt_arr = np.array(gt_gray) / 255.0

    # Visualization
    vmax = np.percentile(np.concatenate([gt_arr.flatten(), final_prediction.flatten()]), 99)

    fig, axes = plt.subplots(1, 2, figsize=(16, 8))
    axes[0].imshow(gt_arr, cmap='inferno', vmin=0, vmax=vmax)
    axes[0].set_title(f"GT #{i+1}")
    axes[0].axis('off')

    axes[1].imshow(final_prediction, cmap='inferno', vmin=0, vmax=vmax)
    axes[1].set_title(f"Prediction #{i+1}")
    axes[1].axis('off')

    plt.tight_layout()
    plt.show()